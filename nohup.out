Traceback (most recent call last):
  File "run_cite.py", line 10, in <module>
    from transformers import BertConfig, BertTokenizer, BertForMaskedLM
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/__init__.py", line 2098, in __getattr__
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/file_utils.py", line 1465, in __getattr__
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/file_utils.py", line 1464, in __getattr__
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/models/bert/__init__.py", line 134, in _get_module
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 618, in _load_backward_compatible
  File "<frozen zipimport>", line 259, in load_module
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/models/bert/modeling_bert.py", line 49, in <module>
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 618, in _load_backward_compatible
  File "<frozen zipimport>", line 259, in load_module
  File "/home/ohagi_masaya/anaconda3/envs/py38/lib/python3.8/site-packages/transformers-4.2.2-py3.8.egg/transformers/modeling_utils.py", line 43, in <module>
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap>", line 618, in _load_backward_compatible
  File "<frozen zipimport>", line 241, in load_module
  File "<frozen zipimport>", line 713, in _get_module_code
  File "<frozen zipimport>", line 647, in _compile_source
KeyboardInterrupt
Traceback (most recent call last):
  File "run_cite.py", line 10, in <module>
    from transformers import BertConfig, BertTokenizer, BertForMaskedLM
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/transformers/__init__.py", line 21, in <module>
    from .configuration_albert import ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP, AlbertConfig
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/transformers/configuration_albert.py", line 18, in <module>
    from .configuration_utils import PretrainedConfig
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/transformers/configuration_utils.py", line 24, in <module>
    from .file_utils import CONFIG_NAME, cached_path, hf_bucket_url, is_remote_url
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/transformers/file_utils.py", line 28, in <module>
    import requests
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/requests/__init__.py", line 44, in <module>
    import chardet
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/chardet/__init__.py", line 19, in <module>
    from .universaldetector import UniversalDetector
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/chardet/universaldetector.py", line 47, in <module>
    from .mbcsgroupprober import MBCSGroupProber
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/chardet/mbcsgroupprober.py", line 32, in <module>
    from .sjisprober import SJISProber
  File "/home/ohagi_masaya/.pyenv/versions/anaconda3-2019.10/envs/py38/lib/python3.8/site-packages/chardet/sjisprober.py", line 30, in <module>
    from .chardistribution import SJISDistributionAnalysis
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 779, in exec_module
  File "<frozen importlib._bootstrap_external>", line 874, in get_code
  File "<frozen importlib._bootstrap_external>", line 973, in get_data
KeyboardInterrupt
Some weights of the model checkpoint at /home/ohagi_masaya/TransBasedCitEmb/pretrainedmodel/scibert_scivocab_uncased were not used when initializing PTBCN: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing PTBCN from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing PTBCN from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of PTBCN were not initialized from the model checkpoint at /home/ohagi_masaya/TransBasedCitEmb/pretrainedmodel/scibert_scivocab_uncased and are newly initialized: ['cls.predictions.decoder.bias', 'ent_lm_head.dense.weight', 'ent_lm_head.dense.bias', 'ent_lm_head.layer_norm.gamma', 'ent_lm_head.layer_norm.beta', 'ent_lm_head.decoder.weight', 'ent_embeddings.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
arguments
Namespace(MAX_LEN=256, WINDOW_SIZE=125, batch_size=16, dataset='AASC', epoch=5, final_layer='feedforward', frequency=5, gamma=0.8, loss_type='CrossEntropy', lr=5e-05, mask_type='tail', predict=True, pretrained_model='scibert', test_data='excluded', train=False, train_data='excluded')
----loading data done----
parameters of SciBERT has been loaded.
GPU OK
model_epoch5_batchsize16_learningrate5e-05_dataAASC_WINDOWSIZE125_MAXLEN256_pretrainedmodelscibert_tail_feedforward_CrossEntropy.bin
train start
train end
501
0.6360783449344314
1002
0.5073418875213833
1503
0.45152442001363513
2004
0.4188909505972548
2505
0.3985580798252829
3006
0.37757153715472525
3507
0.41164801549540636
4008
0.41733152473910606
4509
0.42650762420935984
5010
0.42044828511252147
5511
0.407245948626357
6012
0.40211308899124587
6513
0.4011174682528035
7014
0.39617169403226193
7515
0.3936268963294893
8016
0.3894837995074878
8517
0.3880414106060329
9018
0.38645368419587617
9519
0.38466347713892773
10020
0.37970969839798097
10521
0.3749315377729426
11022
0.3700884623866576
11523
0.366339800776453
12024
0.36291095098387066
12525
0.35956945780632993
13026
0.356859169783898
13527
0.3548041651790022
14028
0.35146199213205925
14529
0.34873402306502116
15030
0.3462194839916759
15531
0.3445506691570429
16032
0.34410819018680106
16533
0.34278071179880226
17034
0.34105966446109826
17535
0.3426032871011168
18036
0.3415178982205942
18537
0.33968998848929793
19038
0.33819102149119934
19539
0.3375559900425245
20040
0.33598306662762434
20541
0.3350621776434705
21042
0.33418575839786824
21543
0.3373786040329158
22044
0.33812488334703683
22545
0.33646110311182525
23046
0.33469066334349706
23547
0.3330293657317077
24048
0.3317899977908366
24549
0.3307620092748829
25050
0.3290439728127685
25551
0.3276828571964839
26052
0.3286709832555974
26553
0.3279193911685501
27054
0.32724898274589165
27555
0.32585709003983104
28056
0.3242556895007126
MRR
0.32396706829127553
Recallat5
0.44978522489261247
Recallat10
0.5565692782846391
Recallat30
0.712236856118428
MAP
0.30782657457286444

lens
5172
5172
1284
1284
0 1.5309252738952637
1000 7.74877013476236
2000 12.513237284612124
3000 12.527355890705653
4000 12.575126627179529
5000 12.937584449482346
0 3.968196678161621
1000 12.843548806827844
SVM data load done
training start
PCA start
PCA done: 1284
Y length: 1284
visualization start
5172
5172
training done
正解率＝ 0.8387850467289719
マクロ平均＝ 0.7380294666190199
ミクロ平均＝ 0.838785046728972
Counter({0: 539, 4: 125, 10: 124, 6: 106, 8: 101, 3: 60, 2: 56, 9: 54, 7: 43, 11: 42, 1: 21, 5: 13})
正解率＝ 0.7515576323987538
マクロ平均＝ 0.6263757855813682
ミクロ平均＝ 0.7515576323987538
Counter({0: 750, 10: 106, 4: 102, 6: 81, 8: 68, 3: 44, 9: 40, 2: 39, 11: 24, 7: 15, 1: 9, 5: 6})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.8208722741433022
マクロ平均＝ 0.7213449625484265
ミクロ平均＝ 0.8208722741433022
Counter({0: 536, 4: 124, 10: 119, 6: 106, 8: 92, 3: 62, 2: 59, 9: 52, 7: 50, 11: 47, 1: 21, 5: 16})
正解率＝ 0.7476635514018691
マクロ平均＝ 0.6262395357604599
ミクロ平均＝ 0.7476635514018691
Counter({0: 753, 10: 106, 4: 101, 6: 80, 8: 68, 3: 42, 9: 40, 2: 39, 11: 24, 7: 15, 1: 9, 5: 7})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.8169781931464174
マクロ平均＝ 0.7194992592089561
ミクロ平均＝ 0.8169781931464174
Counter({0: 537, 4: 124, 10: 119, 6: 105, 8: 92, 3: 59, 2: 59, 9: 54, 7: 51, 11: 46, 1: 21, 5: 17})
正解率＝ 0.7476635514018691
マクロ平均＝ 0.6262395357604599
ミクロ平均＝ 0.7476635514018691
Counter({0: 753, 10: 106, 4: 101, 6: 80, 8: 68, 3: 42, 9: 40, 2: 39, 11: 24, 7: 15, 1: 9, 5: 7})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
正解率＝ 0.40809968847352024
マクロ平均＝ 0.049547093733140236
ミクロ平均＝ 0.40809968847352024
Counter({0: 1283, 4: 1})
